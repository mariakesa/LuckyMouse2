{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cd57a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "from skbio.stats.composition import clr\n",
    "\n",
    "# ─── Load Data ───────────────────────────────────────────────────────────────\n",
    "dataset_path_dict = {\n",
    "    \"embeddings\": \"/home/maria/Documents/HuggingMouseData/MouseViTEmbeddings/google_vit-base-patch16-224_embeddings_logits.pkl\",\n",
    "    \"neural\": \"/home/maria/LuckyMouse2/pixel_transformer_neuro/data/processed/hybrid_neural_responses_reduced.npy\"\n",
    "}\n",
    "\n",
    "with open(dataset_path_dict['embeddings'], \"rb\") as f:\n",
    "    embeddings_raw = pickle.load(f)\n",
    "embeddings = embeddings_raw['natural_scenes']  # shape: (118, 1000)\n",
    "print(\"Full embedding shape:\", embeddings.shape)\n",
    "\n",
    "neural_data = np.load(dataset_path_dict[\"neural\"])  # shape: (neurons, 118)\n",
    "\n",
    "# ─── Split Train/Test ────────────────────────────────────────────────────────\n",
    "n_train = 100\n",
    "X_train_raw = embeddings[:n_train]\n",
    "X_test_raw = embeddings[n_train:]\n",
    "\n",
    "# ─── Fit PCA only on training set ────────────────────────────────────────────\n",
    "pca = PCA(n_components=50, whiten=True)\n",
    "X_train = pca.fit_transform(X_train_raw)\n",
    "X_test = pca.transform(X_test_raw)\n",
    "print(\"Train PCA shape:\", X_train.shape)\n",
    "print(\"Test PCA shape:\", X_test.shape)\n",
    "\n",
    "# ─── Add Intercept ───────────────────────────────────────────────────────────\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "# ─── Fit Model ───────────────────────────────────────────────────────────────\n",
    "n_neurons = neural_data.shape[0]\n",
    "n_trials = 50\n",
    "r2_test_scores = []\n",
    "\n",
    "for i in range(n_neurons):\n",
    "    counts = neural_data[i]\n",
    "\n",
    "    # Split target variable\n",
    "    y_train = np.clip(np.round(counts[:n_train]), 0, n_trials)\n",
    "    y_test = np.clip(np.round(counts[n_train:]), 0, n_trials)\n",
    "    y_train_binomial = np.column_stack([y_train, n_trials - y_train])\n",
    "\n",
    "    try:\n",
    "        model = sm.GLM(y_train_binomial, X_train, family=sm.families.Binomial())\n",
    "        result = model.fit_regularized(alpha=10.0, L1_wt=0)\n",
    "\n",
    "        probs_pred = result.predict(X_test)\n",
    "        counts_pred = n_trials * probs_pred\n",
    "        r2_count = r2_score(y_test, counts_pred)\n",
    "        r2_test_scores.append(r2_count)\n",
    "\n",
    "        probs_true = y_test / n_trials\n",
    "        r2_prob = r2_score(probs_true, probs_pred)\n",
    "\n",
    "        print(f\"Neuron {i}: R² (counts) = {r2_count:.4f} | R² (probs) = {r2_prob:.4f}\")\n",
    "        print(\"True counts:\", y_test)\n",
    "        print(\"Predicted counts:\", counts_pred.round(2))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Neuron {i}: Error - {e}\")\n",
    "        r2_test_scores.append(None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Global 3.10)",
   "language": "python",
   "name": "global-310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
