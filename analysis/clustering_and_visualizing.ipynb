{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdced5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria/global_venv/lib/python3.12/site-packages/umap/umap_.py:1952: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n",
      "Computing log-likelihoods: 100%|██████████| 39209/39209 [00:30<00:00, 1301.90it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pickle\n",
    "from umap import UMAP\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import plotly.io as pio\n",
    "\n",
    "# Use your GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pio.renderers.default = \"browser\"\n",
    "\n",
    "# ---- Model Definition ----\n",
    "class AttentionNullModel(nn.Module):\n",
    "    def __init__(self, vit_dim, neuron_embed_dim, num_neurons, attention_dim, mlp_dim=128):\n",
    "        super().__init__()\n",
    "        self.neuron_embedding = nn.Embedding(num_neurons, neuron_embed_dim)\n",
    "        self.input_proj = nn.Linear(vit_dim + neuron_embed_dim, attention_dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=attention_dim, num_heads=1, batch_first=True)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.LayerNorm(attention_dim),\n",
    "            nn.Linear(attention_dim, mlp_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_dim, attention_dim)\n",
    "        )\n",
    "        self.out = nn.Linear(attention_dim, 1)\n",
    "\n",
    "    def forward(self, image_embedding, neuron_idx):\n",
    "        neuron_emb = self.neuron_embedding(neuron_idx)\n",
    "        x = torch.cat([image_embedding, neuron_emb], dim=-1)\n",
    "        x = self.input_proj(x).unsqueeze(1)\n",
    "        attn_out, _ = self.attn(x, x, x)\n",
    "        mlp_out = self.mlp(attn_out)\n",
    "        final = attn_out + mlp_out\n",
    "        return self.out(final.squeeze(1))  # (B,)\n",
    "\n",
    "# ---- Paths ----\n",
    "model_path = \"/home/maria/LuckyMouse2/saved_models/fold_0/model.pt\"\n",
    "embeddings_path = \"/home/maria/LuckyMouse2/pixel_transformer_neuro/data/processed/google_vit-base-patch16-224_embeddings_softmax.pkl\"\n",
    "\n",
    "# ---- Load ViT stimulus embeddings ----\n",
    "with open(embeddings_path, \"rb\") as f:\n",
    "    vit_data = pickle.load(f)['natural_scenes']\n",
    "vit_embeddings = torch.tensor(vit_data, dtype=torch.float32).to(device)  # (num_images, vit_dim)\n",
    "\n",
    "# ---- Load Model ----\n",
    "model = AttentionNullModel(\n",
    "    vit_dim=1000,\n",
    "    neuron_embed_dim=64,\n",
    "    num_neurons=39209,\n",
    "    attention_dim=128\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# ---- Get Neuron Embeddings ----\n",
    "with torch.no_grad():\n",
    "    neuron_embeddings = model.neuron_embedding.weight.cpu().numpy()  # (39209, 64)\n",
    "\n",
    "# ---- UMAP + KMeans ----\n",
    "umap = UMAP(n_components=3, random_state=42)\n",
    "neuron_embeddings_umap = umap.fit_transform(neuron_embeddings)\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(neuron_embeddings_umap)\n",
    "\n",
    "# ---- Compute Log-likelihood Proxy (Negative MSE) per neuron ----\n",
    "log_likelihoods = np.zeros(model.neuron_embedding.num_embeddings)\n",
    "batch_size = 512\n",
    "\n",
    "with torch.no_grad():\n",
    "    for neuron_id in tqdm(range(model.neuron_embedding.num_embeddings), desc=\"Computing log-likelihoods\"):\n",
    "        preds = []\n",
    "        for i in range(0, vit_embeddings.shape[0], batch_size):\n",
    "            batch_images = vit_embeddings[i:i+batch_size]\n",
    "            batch_neuron_idx = torch.full((batch_images.size(0),), neuron_id, dtype=torch.long).to(device)\n",
    "            out = model(batch_images, batch_neuron_idx)\n",
    "            preds.append(out.cpu())\n",
    "\n",
    "        preds = torch.cat(preds)\n",
    "        mse = torch.nn.functional.mse_loss(preds, torch.zeros_like(preds), reduction='mean')\n",
    "        log_likelihoods[neuron_id] = -mse.item()\n",
    "\n",
    "# ---- Plot in UMAP space ----\n",
    "fig = px.scatter_3d(\n",
    "    x=neuron_embeddings_umap[:, 0],\n",
    "    y=neuron_embeddings_umap[:, 1],\n",
    "    z=neuron_embeddings_umap[:, 2],\n",
    "    color=log_likelihoods,\n",
    "    title=\"Neuron Embeddings (UMAP) Colored by Log-Likelihood\",\n",
    "    labels={\"x\": \"UMAP-1\", \"y\": \"UMAP-2\", \"z\": \"UMAP-3\"},\n",
    "    color_continuous_scale=\"Viridis\"\n",
    ")\n",
    "fig.update_traces(marker=dict(size=2))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e5f1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria/global_venv/lib/python3.12/site-packages/umap/umap_.py:1952: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n",
      "Computing average probabilities: 100%|██████████| 39209/39209 [00:22<00:00, 1746.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pickle\n",
    "from umap import UMAP\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "import plotly.io as pio\n",
    "\n",
    "# Use browser for plots\n",
    "pio.renderers.default = \"browser\"\n",
    "\n",
    "# ---- Setup ----\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---- Model Definition ----\n",
    "class AttentionNullModel(nn.Module):\n",
    "    def __init__(self, vit_dim, neuron_embed_dim, num_neurons, attention_dim, mlp_dim=128):\n",
    "        super().__init__()\n",
    "        self.neuron_embedding = nn.Embedding(num_neurons, neuron_embed_dim)\n",
    "        self.input_proj = nn.Linear(vit_dim + neuron_embed_dim, attention_dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=attention_dim, num_heads=1, batch_first=True)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.LayerNorm(attention_dim),\n",
    "            nn.Linear(attention_dim, mlp_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_dim, attention_dim)\n",
    "        )\n",
    "        self.out = nn.Linear(attention_dim, 1)\n",
    "\n",
    "    def forward(self, image_embedding, neuron_idx):\n",
    "        neuron_emb = self.neuron_embedding(neuron_idx)\n",
    "        x = torch.cat([image_embedding, neuron_emb], dim=-1)\n",
    "        x = self.input_proj(x).unsqueeze(1)\n",
    "        attn_out, _ = self.attn(x, x, x)\n",
    "        mlp_out = self.mlp(attn_out)\n",
    "        final = attn_out + mlp_out\n",
    "        return self.out(final.squeeze(1))  # (B,)\n",
    "\n",
    "# ---- Paths ----\n",
    "model_path = \"/home/maria/LuckyMouse2/saved_models/fold_0/model.pt\"\n",
    "embeddings_path = \"/home/maria/LuckyMouse2/pixel_transformer_neuro/data/processed/google_vit-base-patch16-224_embeddings_softmax.pkl\"\n",
    "\n",
    "# ---- Load ViT stimulus embeddings ----\n",
    "with open(embeddings_path, \"rb\") as f:\n",
    "    vit_data = pickle.load(f)['natural_scenes']\n",
    "vit_embeddings = torch.tensor(vit_data, dtype=torch.float32).to(device)\n",
    "\n",
    "# ---- Load Model ----\n",
    "model = AttentionNullModel(\n",
    "    vit_dim=1000,\n",
    "    neuron_embed_dim=64,\n",
    "    num_neurons=39209,\n",
    "    attention_dim=128\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# ---- Get Neuron Embeddings ----\n",
    "with torch.no_grad():\n",
    "    neuron_embeddings = model.neuron_embedding.weight.cpu().numpy()  # (39209, 64)\n",
    "\n",
    "# ---- UMAP + KMeans ----\n",
    "umap = UMAP(n_components=3, random_state=42)\n",
    "neuron_embeddings_umap = umap.fit_transform(neuron_embeddings)\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(neuron_embeddings_umap)\n",
    "\n",
    "# ---- Compute average predicted probability per neuron ----\n",
    "average_probs = np.zeros(model.neuron_embedding.num_embeddings)\n",
    "batch_size = 512\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for neuron_id in tqdm(range(model.neuron_embedding.num_embeddings), desc=\"Computing average probabilities\"):\n",
    "        probs = []\n",
    "        for i in range(0, vit_embeddings.size(0), batch_size):\n",
    "            batch_images = vit_embeddings[i:i+batch_size]\n",
    "            batch_neuron_idx = torch.full((batch_images.size(0),), neuron_id, dtype=torch.long).to(device)\n",
    "            out = model(batch_images, batch_neuron_idx)\n",
    "            probs.append(sigmoid(out).cpu())\n",
    "\n",
    "        probs = torch.cat(probs)\n",
    "        average_probs[neuron_id] = probs.mean().item()\n",
    "\n",
    "# ---- UMAP 3D Plot colored by average probability ----\n",
    "fig_3d = px.scatter_3d(\n",
    "    x=neuron_embeddings_umap[:, 0],\n",
    "    y=neuron_embeddings_umap[:, 1],\n",
    "    z=neuron_embeddings_umap[:, 2],\n",
    "    color=average_probs,\n",
    "    title=\"Neuron Embeddings (UMAP) Colored by Avg Probability\",\n",
    "    labels={\"x\": \"UMAP-1\", \"y\": \"UMAP-2\", \"z\": \"UMAP-3\"},\n",
    "    color_continuous_scale=\"Viridis\"\n",
    ")\n",
    "fig_3d.update_traces(marker=dict(size=2))\n",
    "fig_3d.show()\n",
    "\n",
    "# ---- Compute average probability per cluster ----\n",
    "cluster_avg_probs = []\n",
    "for c in range(kmeans.n_clusters):\n",
    "    cluster_avg_probs.append(average_probs[cluster_labels == c].mean())\n",
    "\n",
    "# ---- Bar Chart of Avg Probability per Cluster ----\n",
    "fig_bar = go.Figure()\n",
    "fig_bar.add_trace(go.Bar(\n",
    "    x=[f\"Cluster {i}\" for i in range(kmeans.n_clusters)],\n",
    "    y=cluster_avg_probs,\n",
    "    marker_color='indigo'\n",
    "))\n",
    "fig_bar.update_layout(\n",
    "    title=\"Average Predicted Probability per Neuron Cluster\",\n",
    "    xaxis_title=\"Cluster\",\n",
    "    yaxis_title=\"Average Probability\",\n",
    "    yaxis_range=[0, 1],\n",
    ")\n",
    "fig_bar.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f54835b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "def plot_probability_histograms_by_cluster(average_probs, cluster_labels, num_bins=30):\n",
    "    \"\"\"\n",
    "    Plots one histogram per cluster showing the distribution of average probabilities.\n",
    "    \n",
    "    Parameters:\n",
    "        average_probs (np.ndarray): Array of shape (n_neurons,) with average probabilities.\n",
    "        cluster_labels (np.ndarray): Array of shape (n_neurons,) with KMeans cluster labels.\n",
    "        num_bins (int): Number of histogram bins per plot.\n",
    "    \"\"\"\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=len(unique_clusters),\n",
    "        subplot_titles=[f\"Cluster {c}\" for c in unique_clusters],\n",
    "        shared_yaxes=True\n",
    "    )\n",
    "\n",
    "    for i, c in enumerate(unique_clusters):\n",
    "        cluster_probs = average_probs[cluster_labels == c]\n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=cluster_probs,\n",
    "                nbinsx=num_bins,\n",
    "                name=f\"Cluster {c}\",\n",
    "                marker=dict(color=px.colors.qualitative.Plotly[i % 10])\n",
    "            ),\n",
    "            row=1, col=i+1\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=\"Histogram of Average Predicted Probabilities per Cluster\",\n",
    "        showlegend=False,\n",
    "        height=400,\n",
    "        width=300 * len(unique_clusters),\n",
    "        bargap=0.1,\n",
    "        xaxis_title=\"Avg Probability\"\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "plot_probability_histograms_by_cluster(average_probs, cluster_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Global 3.10)",
   "language": "python",
   "name": "global-310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
